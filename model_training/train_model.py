"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
åŒ…å«æ•°æ®éªŒè¯ã€ç‰¹å¾æå–ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²çš„å®Œæ•´æµç¨‹
"""
import os
import sys
import yaml
import pickle
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data_processor.hybrid_storage import HybridStorage
from data_processor.feature_extractor import FeatureExtractor
from models.hybrid_model import HybridRecommender
from utils.logger import setup_logger

logger = setup_logger(__name__)


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'config.yaml')
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def validate_data(date: str, **context) -> bool:
    """
    éªŒè¯æ•°æ®è´¨é‡
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
    
    Returns:
        æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    """
    logger.info(f"=" * 60)
    logger.info(f"Task 1: éªŒè¯æ•°æ®è´¨é‡ - {date}")
    logger.info(f"=" * 60)
    
    try:
        config = load_config()
        storage = HybridStorage(config)
        
        if config.get('storage_mode') == 'aws':
            # AWSæ¨¡å¼ï¼šéªŒè¯S3æ•°æ®
            events = storage.s3_storage.read_raw_events_by_date(date)
            
            if len(events) == 0:
                logger.warning(f"æ—¥æœŸ {date} æ²¡æœ‰æ•°æ®")
                return False
            
            # éªŒè¯æ•°æ®æ ¼å¼
            for event in events[:100]:  # æŠ½æ ·éªŒè¯
                assert 'user_id' in event
                assert 'movie_id' in event
                assert 'rating' in event
                assert 1.0 <= event['rating'] <= 5.0
            
            logger.info(f"âœ“ æ•°æ®éªŒè¯é€šè¿‡: {len(events)} æ¡è®°å½•")
        else:
            # SQLiteæ¨¡å¼ï¼šéªŒè¯æ•°æ®åº“
            ratings = storage.sqlite_storage.get_all_ratings()
            logger.info(f"âœ“ æ•°æ®éªŒè¯é€šè¿‡: {len(ratings)} æ¡è®°å½•")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æ•°æ®éªŒè¯å¤±è´¥: {e}")
        raise


def extract_features_batch(date: str, **context) -> Dict:
    """
    æ‰¹é‡æå–ç‰¹å¾
    
    Args:
        date: æ—¥æœŸå­—ç¬¦ä¸²
    
    Returns:
        ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    """
    logger.info(f"=" * 60)
    logger.info(f"Task 2: æ‰¹é‡æå–ç‰¹å¾ - {date}")
    logger.info(f"=" * 60)
    
    try:
        config = load_config()
        storage = HybridStorage(config)
        
        # è¯»å–æ‰€æœ‰è¯„åˆ†æ•°æ®
        all_ratings = storage.get_all_ratings()
        logger.info(f"è¯»å–è¯„åˆ†æ•°æ®: {len(all_ratings)} æ¡")
        
        # æ„å»ºè¯„åˆ†DataFrame
        df = pd.DataFrame(all_ratings, columns=['user_id', 'movie_id', 'rating', 'timestamp'])
        
        # è®¡ç®—ç”¨æˆ·ç‰¹å¾
        logger.info("è®¡ç®—ç”¨æˆ·ç‰¹å¾...")
        user_features = df.groupby('user_id').agg({
            'rating': ['mean', 'count', 'std']
        }).reset_index()
        user_features.columns = ['user_id', 'avg_rating', 'rating_count', 'std_dev']
        user_features['std_dev'] = user_features['std_dev'].fillna(0)
        
        # è®¡ç®—ç”µå½±ç‰¹å¾
        logger.info("è®¡ç®—ç”µå½±ç‰¹å¾...")
        movie_features = df.groupby('movie_id').agg({
            'rating': ['mean', 'count']
        }).reset_index()
        movie_features.columns = ['movie_id', 'avg_rating', 'rating_count']
        movie_features['popularity'] = np.log1p(movie_features['rating_count'])
        
        # æ›´æ–°åˆ°å­˜å‚¨å±‚
        logger.info("æ›´æ–°ç‰¹å¾åˆ°å­˜å‚¨å±‚...")
        for _, row in user_features.iterrows():
            storage.update_user_feature(
                int(row['user_id']),
                float(row['avg_rating']),
                int(row['rating_count']),
                float(row['std_dev'])
            )
        
        for _, row in movie_features.iterrows():
            storage.update_movie_feature(
                int(row['movie_id']),
                float(row['avg_rating']),
                int(row['rating_count']),
                float(row['popularity'])
            )
        
        stats = {
            'user_count': len(user_features),
            'movie_count': len(movie_features),
            'rating_count': len(all_ratings),
            'date': date
        }
        
        logger.info(f"âœ“ ç‰¹å¾æå–å®Œæˆ: {stats}")
        
        # æ¨é€åˆ°XComä¾›ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨
        context['task_instance'].xcom_push(key='feature_stats', value=stats)
        
        return stats
        
    except Exception as e:
        logger.error(f"âœ— ç‰¹å¾æå–å¤±è´¥: {e}")
        raise


def train_hybrid_model(**context) -> str:
    """
    è®­ç»ƒæ··åˆæ¨èæ¨¡å‹
    
    Returns:
        æ¨¡å‹ä¿å­˜è·¯å¾„
    """
    logger.info(f"=" * 60)
    logger.info(f"Task 3: è®­ç»ƒæ··åˆæ¨èæ¨¡å‹")
    logger.info(f"=" * 60)
    
    try:
        config = load_config()
        storage = HybridStorage(config)
        
        # æ„å»ºè¯„åˆ†çŸ©é˜µ
        logger.info("æ„å»ºç”¨æˆ·-ç”µå½±è¯„åˆ†çŸ©é˜µ...")
        if config.get('storage_mode') == 'sqlite':
            feature_extractor = FeatureExtractor(storage.sqlite_storage)
        else:
            feature_extractor = FeatureExtractor(storage)
        
        rating_matrix, user_id_to_idx, movie_id_to_idx = feature_extractor.build_user_item_matrix()
        
        logger.info(f"è¯„åˆ†çŸ©é˜µå½¢çŠ¶: {rating_matrix.shape}")
        logger.info(f"ç”¨æˆ·æ•°: {len(user_id_to_idx)}")
        logger.info(f"ç”µå½±æ•°: {len(movie_id_to_idx)}")
        
        # è®­ç»ƒæ¨¡å‹
        logger.info("è®­ç»ƒæ··åˆæ¨èæ¨¡å‹...")
        model = HybridRecommender(rating_matrix, config['model'])
        
        # ä¿å­˜æ¨¡å‹
        model_dir = 'models/saved_models'
        os.makedirs(model_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        model_path = f'{model_dir}/hybrid_model_{timestamp}.pkl'
        
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': model,
                'rating_matrix': rating_matrix,
                'user_id_to_idx': user_id_to_idx,
                'movie_id_to_idx': movie_id_to_idx,
                'config': config['model'],
                'timestamp': timestamp
            }, f)
        
        logger.info(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # æ¨é€æ¨¡å‹è·¯å¾„åˆ°XCom
        context['task_instance'].xcom_push(key='model_path', value=model_path)
        
        return model_path
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        raise


def split_train_test(rating_matrix: pd.DataFrame, test_ratio: float = 0.2) -> Tuple[pd.DataFrame, Dict]:
    """
    å°†æ¯ä¸ªç”¨æˆ·çš„è¯„åˆ†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    
    Args:
        rating_matrix: ç”¨æˆ·-ç”µå½±è¯„åˆ†çŸ©é˜µ
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹
    
    Returns:
        train_matrix: è®­ç»ƒé›†è¯„åˆ†çŸ©é˜µ
        test_data: æµ‹è¯•é›†å­—å…¸ {user_id: [(movie_id, rating), ...]}
    """
    train_matrix = rating_matrix.copy()
    test_data = {}
    
    for user_id in rating_matrix.index:
        user_ratings = rating_matrix.loc[user_id]
        # è·å–ç”¨æˆ·è¯„è¿‡åˆ†çš„ç”µå½±
        rated_movies = user_ratings[user_ratings > 0]
        
        if len(rated_movies) < 5:  # è¯„åˆ†å¤ªå°‘çš„ç”¨æˆ·ä¸åˆ’åˆ†
            continue
        
        # éšæœºé€‰æ‹©æµ‹è¯•é›†
        n_test = max(1, int(len(rated_movies) * test_ratio))
        test_movies = rated_movies.sample(n=n_test, random_state=42)
        
        # ä¿å­˜æµ‹è¯•æ•°æ®
        test_data[user_id] = [(movie_id, rating) for movie_id, rating in test_movies.items()]
        
        # ä»è®­ç»ƒé›†ä¸­ç§»é™¤æµ‹è¯•æ•°æ®
        train_matrix.loc[user_id, test_movies.index] = 0
    
    return train_matrix, test_data


def calculate_precision_recall_f1(recommended: List[int], relevant: List[int], k: int) -> Tuple[float, float, float]:
    """
    è®¡ç®— Precision@K, Recall@K, F1@K
    
    Args:
        recommended: æ¨èçš„ç”µå½±IDåˆ—è¡¨
        relevant: ç›¸å…³ï¼ˆç”¨æˆ·å–œæ¬¢ï¼‰çš„ç”µå½±IDåˆ—è¡¨
        k: Top-K
    
    Returns:
        precision, recall, f1
    """
    if not recommended or not relevant:
        return 0.0, 0.0, 0.0
    
    recommended_k = set(recommended[:k])
    relevant_set = set(relevant)
    
    # æ¨èåˆ—è¡¨ä¸­ç›¸å…³çš„ç‰©å“æ•°é‡
    hits = len(recommended_k & relevant_set)
    
    precision = hits / len(recommended_k) if recommended_k else 0.0
    recall = hits / len(relevant_set) if relevant_set else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    return precision, recall, f1


def calculate_ndcg(recommended: List[int], relevant: List[int], k: int) -> float:
    """
    è®¡ç®— NDCG@K (Normalized Discounted Cumulative Gain)
    
    Args:
        recommended: æ¨èçš„ç”µå½±IDåˆ—è¡¨
        relevant: ç›¸å…³ï¼ˆç”¨æˆ·å–œæ¬¢ï¼‰çš„ç”µå½±IDåˆ—è¡¨
        k: Top-K
    
    Returns:
        NDCG@K åˆ†æ•°
    """
    if not recommended or not relevant:
        return 0.0
    
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    
    # DCG: ç´¯ç§¯æŠ˜æ‰£å¢ç›Š
    dcg = 0.0
    for i, movie_id in enumerate(recommended_k):
        if movie_id in relevant_set:
            # ç›¸å…³æ€§ä¸º1ï¼Œä½ç½®i+1
            dcg += 1.0 / np.log2(i + 2)  # i+2 å› ä¸ºä½ç½®ä»1å¼€å§‹
    
    # IDCG: ç†æƒ³æƒ…å†µä¸‹çš„DCGï¼ˆæ‰€æœ‰ç›¸å…³ç‰©å“éƒ½åœ¨å‰é¢ï¼‰
    idcg = 0.0
    for i in range(min(len(relevant), k)):
        idcg += 1.0 / np.log2(i + 2)
    
    ndcg = dcg / idcg if idcg > 0 else 0.0
    return ndcg


def calculate_hit_rate(recommended: List[int], relevant: List[int], k: int) -> float:
    """
    è®¡ç®— Hit Rate@K (å‘½ä¸­ç‡)
    
    Args:
        recommended: æ¨èçš„ç”µå½±IDåˆ—è¡¨
        relevant: ç›¸å…³ï¼ˆç”¨æˆ·å–œæ¬¢ï¼‰çš„ç”µå½±IDåˆ—è¡¨
        k: Top-K
    
    Returns:
        1 å¦‚æœå‘½ä¸­ï¼Œ0 å¦‚æœæœªå‘½ä¸­
    """
    if not recommended or not relevant:
        return 0.0
    
    recommended_k = set(recommended[:k])
    relevant_set = set(relevant)
    
    # åªè¦æ¨èåˆ—è¡¨ä¸­æœ‰è‡³å°‘ä¸€ä¸ªç›¸å…³ç‰©å“å°±ç®—å‘½ä¸­
    return 1.0 if len(recommended_k & relevant_set) > 0 else 0.0


def calculate_diversity(all_recommendations: List[List[int]]) -> float:
    """
    è®¡ç®—æ¨èå¤šæ ·æ€§ï¼ˆä¸åŒæ¨èåˆ—è¡¨ä¹‹é—´çš„å·®å¼‚åº¦ï¼‰
    
    Args:
        all_recommendations: æ‰€æœ‰ç”¨æˆ·çš„æ¨èåˆ—è¡¨
    
    Returns:
        å¤šæ ·æ€§åˆ†æ•° (0-1)
    """
    if len(all_recommendations) < 2:
        return 0.0
    
    # è®¡ç®—æ‰€æœ‰æ¨èå¯¹ä¹‹é—´çš„ä¸ç›¸ä¼¼åº¦
    diversity_scores = []
    for i in range(len(all_recommendations)):
        for j in range(i + 1, len(all_recommendations)):
            set_i = set(all_recommendations[i])
            set_j = set(all_recommendations[j])
            
            # Jaccardè·ç¦» = 1 - Jaccardç›¸ä¼¼åº¦
            union = len(set_i | set_j)
            if union > 0:
                jaccard_similarity = len(set_i & set_j) / union
                diversity_scores.append(1 - jaccard_similarity)
    
    return np.mean(diversity_scores) if diversity_scores else 0.0


def evaluate_model(**context) -> Dict:
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½ - ä½¿ç”¨æ¨èç³»ç»Ÿæ ‡å‡†è¯„ä¼°æŒ‡æ ‡
    
    Returns:
        è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    logger.info(f"=" * 60)
    logger.info(f"Task 4: è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆä½¿ç”¨æ ‡å‡†æ¨èæŒ‡æ ‡ï¼‰")
    logger.info(f"=" * 60)
    
    try:
        # ä»XComè·å–æ¨¡å‹è·¯å¾„
        model_path = context['task_instance'].xcom_pull(task_ids='train_model', key='model_path')
        
        # åŠ è½½æ¨¡å‹
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        model = model_data['model']
        rating_matrix = model_data['rating_matrix']
        
        logger.info(f"è¯„åˆ†çŸ©é˜µå¤§å°: {rating_matrix.shape}")
        logger.info(f"ç”¨æˆ·æ•°: {len(rating_matrix)}, ç”µå½±æ•°: {len(rating_matrix.columns)}")
        
        # 1. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        logger.info("åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
        train_matrix, test_data = split_train_test(rating_matrix, test_ratio=0.2)
        logger.info(f"æµ‹è¯•ç”¨æˆ·æ•°: {len(test_data)}")
        
        # 2. åœ¨è®­ç»ƒé›†ä¸Šé‡å»ºæ¨¡å‹ï¼ˆç”¨äºè¯„ä¼°ï¼‰
        logger.info("åŸºäºè®­ç»ƒé›†é‡å»ºæ¨¡å‹...")
        config = load_config()
        eval_model = HybridRecommender(train_matrix, config['model'])
        
        # 3. è¯„ä¼°å‚æ•°
        k_values = [5, 10, 20]  # è¯„ä¼°ä¸åŒçš„Kå€¼
        rating_threshold = 3.5  # è¯„åˆ†>=3.5è®¤ä¸ºæ˜¯ç›¸å…³/å–œæ¬¢çš„
        
        # 4. æ”¶é›†è¯„ä¼°æ•°æ®
        metrics_by_k = {k: {
            'precision': [],
            'recall': [],
            'f1': [],
            'ndcg': [],
            'hit_rate': []
        } for k in k_values}
        
        all_recommendations = []
        all_recommended_movies = set()
        
        # 5. å¯¹æ¯ä¸ªæµ‹è¯•ç”¨æˆ·è¿›è¡Œè¯„ä¼°
        logger.info("å¼€å§‹è¯„ä¼°...")
        evaluated_users = 0
        
        for user_id, test_items in test_data.items():
            try:
                # è·å–æ¨èåˆ—è¡¨
                recommended = eval_model.recommend(user_id, top_n=max(k_values))
                
                if not recommended:
                    continue
                
                all_recommendations.append(recommended)
                all_recommended_movies.update(recommended)
                
                # ç¡®å®šç›¸å…³ç‰©å“ï¼ˆæµ‹è¯•é›†ä¸­è¯„åˆ†>=é˜ˆå€¼çš„ç”µå½±ï¼‰
                relevant = [movie_id for movie_id, rating in test_items if rating >= rating_threshold]
                
                if not relevant:
                    continue
                
                # è®¡ç®—å„ä¸ªKå€¼ä¸‹çš„æŒ‡æ ‡
                for k in k_values:
                    precision, recall, f1 = calculate_precision_recall_f1(recommended, relevant, k)
                    ndcg = calculate_ndcg(recommended, relevant, k)
                    hit_rate = calculate_hit_rate(recommended, relevant, k)
                    
                    metrics_by_k[k]['precision'].append(precision)
                    metrics_by_k[k]['recall'].append(recall)
                    metrics_by_k[k]['f1'].append(f1)
                    metrics_by_k[k]['ndcg'].append(ndcg)
                    metrics_by_k[k]['hit_rate'].append(hit_rate)
                
                evaluated_users += 1
                
            except Exception as e:
                logger.debug(f"è¯„ä¼°ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"æˆåŠŸè¯„ä¼° {evaluated_users} ä¸ªç”¨æˆ·")
        
        # 6. è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {}
        for k in k_values:
            avg_metrics[f'precision@{k}'] = np.mean(metrics_by_k[k]['precision']) if metrics_by_k[k]['precision'] else 0.0
            avg_metrics[f'recall@{k}'] = np.mean(metrics_by_k[k]['recall']) if metrics_by_k[k]['recall'] else 0.0
            avg_metrics[f'f1@{k}'] = np.mean(metrics_by_k[k]['f1']) if metrics_by_k[k]['f1'] else 0.0
            avg_metrics[f'ndcg@{k}'] = np.mean(metrics_by_k[k]['ndcg']) if metrics_by_k[k]['ndcg'] else 0.0
            avg_metrics[f'hit_rate@{k}'] = np.mean(metrics_by_k[k]['hit_rate']) if metrics_by_k[k]['hit_rate'] else 0.0
        
        # 7. è®¡ç®—è¦†ç›–ç‡å’Œå¤šæ ·æ€§
        coverage = len(all_recommended_movies) / len(rating_matrix.columns)
        diversity = calculate_diversity(all_recommendations)
        
        # 8. æ±‡æ€»æ‰€æœ‰æŒ‡æ ‡
        metrics = {
            # å‡†ç¡®ç‡æŒ‡æ ‡
            **avg_metrics,
            
            # è¦†ç›–ç‡å’Œå¤šæ ·æ€§
            'coverage': coverage,
            'diversity': diversity,
            
            # ç»Ÿè®¡ä¿¡æ¯
            'total_users': len(rating_matrix),
            'total_movies': len(rating_matrix.columns),
            'evaluated_users': evaluated_users,
            'recommended_movies': len(all_recommended_movies),
            
            # æ¨¡å‹ä¿¡æ¯
            'model_path': model_path,
            'timestamp': model_data['timestamp'],
            'rating_threshold': rating_threshold
        }
        
        # 9. æ‰“å°è¯„ä¼°ç»“æœ
        logger.info(f"=" * 60)
        logger.info(f"âœ“ è¯„ä¼°å®Œæˆ - è¯„ä¼°äº† {evaluated_users} ä¸ªç”¨æˆ·")
        logger.info(f"=" * 60)
        
        for k in k_values:
            logger.info(f"\nğŸ“Š Top-{k} æŒ‡æ ‡:")
            logger.info(f"  â€¢ Precision@{k}: {avg_metrics[f'precision@{k}']:.4f}")
            logger.info(f"  â€¢ Recall@{k}: {avg_metrics[f'recall@{k}']:.4f}")
            logger.info(f"  â€¢ F1@{k}: {avg_metrics[f'f1@{k}']:.4f}")
            logger.info(f"  â€¢ NDCG@{k}: {avg_metrics[f'ndcg@{k}']:.4f}")
            logger.info(f"  â€¢ Hit Rate@{k}: {avg_metrics[f'hit_rate@{k}']:.4f}")
        
        logger.info(f"\nğŸ“ˆ ç³»ç»Ÿçº§æŒ‡æ ‡:")
        logger.info(f"  â€¢ è¦†ç›–ç‡ (Coverage): {coverage:.4f} ({len(all_recommended_movies)}/{len(rating_matrix.columns)})")
        logger.info(f"  â€¢ å¤šæ ·æ€§ (Diversity): {diversity:.4f}")
        
        # æ¨é€æŒ‡æ ‡åˆ°XCom
        context['task_instance'].xcom_push(key='metrics', value=metrics)
        
        return metrics
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise


def deploy_model(**context) -> bool:
    """
    éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒ
    
    Returns:
        æ˜¯å¦éƒ¨ç½²æˆåŠŸ
    """
    logger.info(f"=" * 60)
    logger.info(f"Task 5: éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿäº§ç¯å¢ƒ")
    logger.info(f"=" * 60)
    
    try:
        # ä»XComè·å–æ¨¡å‹è·¯å¾„å’Œè¯„ä¼°æŒ‡æ ‡
        model_path = context['task_instance'].xcom_pull(task_ids='train_model', key='model_path')
        metrics = context['task_instance'].xcom_pull(task_ids='evaluate_model', key='metrics')
        
        logger.info(f"å¾…éƒ¨ç½²æ¨¡å‹: {model_path}")
        logger.info(f"\nå½“å‰æ¨¡å‹è¯„ä¼°æŒ‡æ ‡:")
        logger.info(f"  â€¢ Precision@10: {metrics.get('precision@10', 0):.4f}")
        logger.info(f"  â€¢ Recall@10: {metrics.get('recall@10', 0):.4f}")
        logger.info(f"  â€¢ NDCG@10: {metrics.get('ndcg@10', 0):.4f}")
        logger.info(f"  â€¢ Hit Rate@10: {metrics.get('hit_rate@10', 0):.4f}")
        logger.info(f"  â€¢ Coverage: {metrics.get('coverage', 0):.4f}")
        
        # å®šä¹‰æ¨¡å‹è´¨é‡é˜ˆå€¼
        quality_checks = {
            'precision@10': (metrics.get('precision@10', 0), 0.01, "ç²¾ç¡®ç‡è¿‡ä½"),
            'hit_rate@10': (metrics.get('hit_rate@10', 0), 0.1, "å‘½ä¸­ç‡è¿‡ä½"),
            'coverage': (metrics.get('coverage', 0), 0.05, "è¦†ç›–ç‡è¿‡ä½"),
            'evaluated_users': (metrics.get('evaluated_users', 0), 10, "è¯„ä¼°ç”¨æˆ·æ•°å¤ªå°‘")
        }
        
        # æ£€æŸ¥æ¯ä¸ªè´¨é‡æŒ‡æ ‡
        failed_checks = []
        for metric_name, (value, threshold, reason) in quality_checks.items():
            if value < threshold:
                failed_checks.append(f"{metric_name} = {value:.4f} < {threshold} ({reason})")
        
        if failed_checks:
            logger.warning("âš ï¸  æ¨¡å‹è´¨é‡æ£€æŸ¥æœªé€šè¿‡ï¼Œè·³è¿‡éƒ¨ç½²:")
            for fail in failed_checks:
                logger.warning(f"  âœ— {fail}")
            return False
        
        logger.info("âœ“ æ¨¡å‹è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        # åˆ›å»ºç”Ÿäº§æ¨¡å‹è·¯å¾„
        production_model_path = 'models/saved_models/production_model.pkl'
        
        # å¦‚æœå­˜åœ¨æ—§çš„ç”Ÿäº§æ¨¡å‹ï¼Œå¤‡ä»½
        if os.path.exists(production_model_path):
            backup_path = f'{production_model_path}.backup'
            if os.path.exists(backup_path):
                os.remove(backup_path)  # åˆ é™¤æ—§å¤‡ä»½
            os.rename(production_model_path, backup_path)
            logger.info(f"å¤‡ä»½æ—§æ¨¡å‹: {backup_path}")
        
        # å¤åˆ¶æ–°æ¨¡å‹ä¸ºç”Ÿäº§æ¨¡å‹
        import shutil
        shutil.copy(model_path, production_model_path)
        
        logger.info(f"=" * 60)
        logger.info(f"âœ“ æ¨¡å‹éƒ¨ç½²æˆåŠŸ: {production_model_path}")
        logger.info(f"=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹éƒ¨ç½²å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    """æœ¬åœ°æµ‹è¯•"""
    print("å¼€å§‹æœ¬åœ°æµ‹è¯•æ¨¡å‹è®­ç»ƒæµç¨‹...")
    
    # æµ‹è¯•æ•°æ®éªŒè¯
    print("\n1. éªŒè¯æ•°æ®...")
    validate_data(datetime.now().strftime('%Y-%m-%d'))
    
    # æµ‹è¯•ç‰¹å¾æå–
    print("\n2. æå–ç‰¹å¾...")
    context = {'task_instance': type('obj', (object,), {'xcom_push': lambda *args, **kwargs: None})}
    extract_features_batch(datetime.now().strftime('%Y-%m-%d'), **context)
    
    # æµ‹è¯•æ¨¡å‹è®­ç»ƒ
    print("\n3. è®­ç»ƒæ¨¡å‹...")
    model_path = train_hybrid_model(**context)
    
    # æµ‹è¯•æ¨¡å‹è¯„ä¼°
    print("\n4. è¯„ä¼°æ¨¡å‹...")
    context['task_instance'].xcom_pull = lambda *args, **kwargs: model_path if kwargs.get('key') == 'model_path' else {}
    evaluate_model(**context)
    
    # æµ‹è¯•æ¨¡å‹éƒ¨ç½²
    print("\n5. éƒ¨ç½²æ¨¡å‹...")
    deploy_model(**context)
    
    print("\nâœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

