# 评估指标快速参考卡

一页纸快速理解所有评估指标 📊

---

## 📋 指标速查表

| 指标 | 中文名 | 范围 | 越高越好? | 一句话解释 |
|------|--------|------|----------|-----------|
| **Precision@K** | 精确率 | 0-1 | ✅ | 推荐的有多少是对的 |
| **Recall@K** | 召回率 | 0-1 | ✅ | 对的有多少被推荐了 |
| **F1@K** | F1分数 | 0-1 | ✅ | Precision和Recall的平衡 |
| **NDCG@K** | 排序质量 | 0-1 | ✅ | 好的推荐是否排在前面 |
| **Hit Rate@K** | 命中率 | 0-1 | ✅ | 有多少用户至少得到1个好推荐 |
| **Coverage** | 覆盖率 | 0-1 | ⚖️ | 推荐了多少不同的电影 |
| **Diversity** | 多样性 | 0-1 | ⚖️ | 不同用户的推荐有多不同 |

> **说明**: ✅ = 越高越好, ⚖️ = 需要平衡（不是越高越好）

---

## 🎯 场景速查

### 场景1: 推荐10部电影给用户A
```
推荐: [电影1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
用户实际喜欢: [电影2, 5, 11, 15]  (评分≥3.5)
推荐中命中: [电影2, 5]
```

**各指标的值**:
- ✅ **Precision@10** = 2/10 = **0.20** (20%的推荐是对的)
- ✅ **Recall@10** = 2/4 = **0.50** (50%喜欢的被推荐了)
- ✅ **F1@10** = 2×0.2×0.5/(0.2+0.5) = **0.29**
- ✅ **NDCG@10** ≈ **0.85** (相关物品排在第2和第5位，位置不错)
- ✅ **Hit Rate@10** = **1.0** (至少命中了1个)

---

## 🤔 指标对比

### Precision vs Recall

```
情况1: 只推荐5部最有把握的
→ Precision高 (推荐的都对) 
→ Recall低 (遗漏了很多)

情况2: 推荐50部覆盖面广的
→ Precision低 (很多推荐不相关)
→ Recall高 (喜欢的基本都推了)

理想: F1-Score高 (两者平衡)
```

### NDCG vs Precision

```
推荐A: [相关, 不相关, 不相关, 相关, 不相关]
推荐B: [不相关, 不相关, 相关, 相关, 不相关]

Precision: 两者都是 2/5 = 0.4
NDCG: A更高 (相关物品排在更前面)

结论: NDCG考虑排序位置，更真实
```

### Coverage vs Diversity

```
Coverage: 系统推荐了多少不同电影
- 低: 只推热门片，长尾电影没机会
- 高: 各种电影都有机会被推荐

Diversity: 不同用户的推荐有多不同
- 低: 所有用户推荐都差不多
- 高: 每个用户都有个性化推荐

两者都高 = 既个性化又有探索性 ✨
```

---

## 📊 典型值参考

### 新手模型 (需要改进)
```
Precision@10:  0.03-0.08   (3%-8%)
Recall@10:     0.10-0.20   (10%-20%)
NDCG@10:       0.15-0.30
Hit Rate@10:   0.30-0.50   (30%-50%)
Coverage:      0.10-0.20   (10%-20%)
```

### 合格模型 (可以使用)
```
Precision@10:  0.10-0.15   (10%-15%)   ⭐
Recall@10:     0.25-0.40   (25%-40%)
NDCG@10:       0.35-0.50
Hit Rate@10:   0.60-0.75   (60%-75%)   ⭐
Coverage:      0.20-0.35   (20%-35%)   ⭐
```

### 优秀模型 (业界领先)
```
Precision@10:  0.20-0.30+  (20%-30%+)  🌟
Recall@10:     0.45-0.60+  (45%-60%+)
NDCG@10:       0.55-0.70+
Hit Rate@10:   0.80-0.95   (80%-95%)   🌟
Coverage:      0.30-0.50   (30%-50%)   🌟
```

---

## ⚡ 快速诊断

### 问题1: Precision很低 (<0.05)
**原因**: 推荐不准确，大部分推荐都不相关

**解决**:
- [ ] 增加训练数据
- [ ] 提高相似度阈值
- [ ] 调高协同过滤权重
- [ ] 过滤低质量推荐

### 问题2: Recall很低 (<0.15)
**原因**: 遗漏了太多用户喜欢的物品

**解决**:
- [ ] 增加推荐列表长度(K值)
- [ ] 降低推荐阈值
- [ ] 增加候选物品池
- [ ] 结合多种推荐策略

### 问题3: NDCG低但Precision不低
**原因**: 相关推荐排在后面

**解决**:
- [ ] 优化推荐排序算法
- [ ] 调整评分计算权重
- [ ] 使用Learning to Rank
- [ ] 考虑用户偏好强度

### 问题4: Hit Rate很低 (<0.30)
**原因**: 大部分用户得不到好推荐

**解决**:
- [ ] 检查数据质量
- [ ] 处理冷启动问题
- [ ] 增加热门推荐降级策略
- [ ] 降低相关性阈值

### 问题5: Coverage很低 (<0.10)
**原因**: 只推荐少数热门物品

**解决**:
- [ ] 降低热门物品权重
- [ ] 增加探索策略
- [ ] 提高内容推荐权重
- [ ] 使用多样性重排序

### 问题6: 所有指标都很低
**原因**: 数据或模型有根本问题

**解决**:
- [ ] 检查训练数据是否足够
- [ ] 验证数据格式是否正确
- [ ] 查看日志找错误信息
- [ ] 从简单模型开始调试

---

## 🎓 记忆口诀

```
Precision问"推的准不准"
Recall问"漏了多少个"
F1是两者平衡点
NDCG看排序好不好
Hit Rate问能否命中
Coverage看推得全不全
Diversity看是否个性化
```

---

## 📐 计算公式速记

```python
# 推荐了K个，命中了H个，总共有R个相关
Precision@K = H / K
Recall@K = H / R  
F1@K = 2 × P × R / (P + R)
Hit Rate@K = 1 if H > 0 else 0

# NDCG考虑位置权重
DCG = Σ(相关性 / log2(位置+1))
NDCG = DCG / IDCG

# 推荐了U个不同物品，总共M个物品
Coverage = U / M

# 所有推荐对的平均Jaccard距离
Diversity = 1 - Jaccard相似度
```

---

## 🚀 优化优先级

按影响大小排序:

1. **Hit Rate@10** ⭐⭐⭐
   - 最直接衡量用户满意度
   - 首要目标: ≥60%

2. **Precision@10** ⭐⭐⭐
   - 决定用户是否信任推荐
   - 目标: ≥10%

3. **NDCG@10** ⭐⭐
   - 用户更看前几个推荐
   - 目标: ≥0.35

4. **Coverage** ⭐⭐
   - 平衡准确性和多样性
   - 目标: 20%-40%

5. **Recall@10** ⭐
   - 辅助指标
   - 目标: ≥25%

6. **Diversity** ⭐
   - 长期用户体验
   - 目标: ≥0.60

---

## 💡 使用建议

1. **日常监控**: 重点看 Hit Rate@10 和 Precision@10
2. **算法优化**: 参考 NDCG@10 和 F1@10
3. **产品决策**: 平衡 Precision 和 Coverage
4. **长期运营**: 关注 Diversity 防止推荐疲劳

---

## 📚 相关文档

- [EVALUATION_METRICS.md](EVALUATION_METRICS.md) - 详细说明
- [EVALUATION_USAGE.md](EVALUATION_USAGE.md) - 使用指南
- [README.md](README.md) - 项目总览

---

**快速参考，随时查阅！** 🎯


