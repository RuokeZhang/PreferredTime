#!/usr/bin/env python3
"""
Kinesis-Lambdaæ¨èæµç¨‹æµ‹è¯•è„šæœ¬

æ¨¡æ‹Ÿå®Œæ•´çš„æ¨èworkflow:
1. ç”Ÿæˆæ¨èè¯·æ±‚äº‹ä»¶
2. å‘é€åˆ°Kinesis Streamï¼ˆæ¨¡æ‹Ÿï¼‰
3. Lambdaå‡½æ•°å¤„ç†äº‹ä»¶
4. è°ƒç”¨FastAPIæ¨èæœåŠ¡
5. è¿”å›æ¨èç»“æœ

æœ¬åœ°æµ‹è¯•æ—¶ä¸éœ€è¦çœŸå®çš„AWS Kinesisï¼Œç›´æ¥è°ƒç”¨Lambdaå‡½æ•°
"""
import json
import base64
import sys
import os
import time
from datetime import datetime
import uuid

# æ·»åŠ lambdaç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'lambda'))

# å¯¼å…¥Lambdaå¤„ç†å™¨
from recommendation_handler import lambda_handler


class MockContext:
    """æ¨¡æ‹ŸLambda Contextå¯¹è±¡"""
    def __init__(self):
        self.request_id = str(uuid.uuid4())
        self.invoked_function_arn = "arn:aws:lambda:us-east-1:123456789:function:movie-rec-handler"
        self.function_name = "movie-rec-kinesis-handler"
        self.memory_limit_in_mb = "512"
        self.function_version = "$LATEST"


def create_kinesis_event(user_ids, top_n=20):
    """
    åˆ›å»ºæ¨¡æ‹Ÿçš„Kinesis Streamäº‹ä»¶
    
    Args:
        user_ids: ç”¨æˆ·IDåˆ—è¡¨
        top_n: æ¯ä¸ªç”¨æˆ·è¯·æ±‚çš„æ¨èæ•°é‡
    
    Returns:
        Kinesisäº‹ä»¶æ ¼å¼çš„å­—å…¸
    """
    records = []
    
    for user_id in user_ids:
        # åˆ›å»ºæ¨èè¯·æ±‚æ•°æ®
        recommendation_request = {
            "user_id": user_id,
            "top_n": top_n,
            "request_id": str(uuid.uuid4()),
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }
        
        # Kinesisè®°å½•æ ¼å¼ï¼ˆéœ€è¦Base64ç¼–ç ï¼‰
        record = {
            "kinesis": {
                "kinesisSchemaVersion": "1.0",
                "partitionKey": f"user-{user_id}",
                "sequenceNumber": f"495903382714902566085596925383615710959215759891365{user_id:05d}",
                "data": base64.b64encode(
                    json.dumps(recommendation_request).encode()
                ).decode(),
                "approximateArrivalTimestamp": time.time()
            },
            "eventSource": "aws:kinesis",
            "eventVersion": "1.0",
            "eventID": f"shardId-000000000000:495903{user_id}",
            "eventName": "aws:kinesis:record",
            "invokeIdentityArn": "arn:aws:iam::123456789:role/lambda-kinesis-role",
            "awsRegion": "us-east-1",
            "eventSourceARN": "arn:aws:kinesis:us-east-1:123456789:stream/movie-rec-requests"
        }
        
        records.append(record)
    
    return {"Records": records}


def test_single_user():
    """æµ‹è¯•å•ä¸ªç”¨æˆ·æ¨è"""
    print("=" * 80)
    print("æµ‹è¯• 1: å•ä¸ªç”¨æˆ·æ¨è")
    print("=" * 80)
    
    # åˆ›å»ºäº‹ä»¶
    event = create_kinesis_event([1], top_n=10)
    context = MockContext()
    
    # è°ƒç”¨Lambdaå¤„ç†å™¨
    response = lambda_handler(event, context)
    
    # è§£æå“åº”
    body = json.loads(response['body'])
    
    print(f"\nâœ“ Lambdaå“åº”:")
    print(f"  Status Code: {response['statusCode']}")
    print(f"  å¤„ç†æˆåŠŸ: {body['processed']}")
    print(f"  å¤„ç†å¤±è´¥: {body['failed']}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {body['avg_latency_ms']}ms")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {body['cache_hit_rate']}")
    
    if body['results']:
        result = body['results'][0]
        print(f"\nç”¨æˆ· {result['user_id']} çš„æ¨è:")
        print(f"  æ¨èæ•°é‡: {result['count']}")
        print(f"  æ¨èåˆ—è¡¨: {result['recommendations'][:5]}... (å‰5ä¸ª)")
        print(f"  å»¶è¿Ÿ: {result['latency_ms']}ms")
        print(f"  æ¥è‡ªç¼“å­˜: {'æ˜¯' if result['from_cache'] else 'å¦'}")
    
    return body


def test_batch_users():
    """æµ‹è¯•æ‰¹é‡ç”¨æˆ·æ¨è"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: æ‰¹é‡ç”¨æˆ·æ¨èï¼ˆæ¨¡æ‹ŸKinesisæ‰¹å¤„ç†ï¼‰")
    print("=" * 80)
    
    # åˆ›å»º10ä¸ªç”¨æˆ·çš„æ¨èè¯·æ±‚
    user_ids = list(range(1, 11))
    event = create_kinesis_event(user_ids, top_n=20)
    context = MockContext()
    
    print(f"\nå‘é€ {len(user_ids)} ä¸ªæ¨èè¯·æ±‚...")
    
    start_time = time.time()
    response = lambda_handler(event, context)
    total_time = (time.time() - start_time) * 1000
    
    body = json.loads(response['body'])
    
    print(f"\nâœ“ æ‰¹å¤„ç†ç»“æœ:")
    print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.0f}ms")
    print(f"  å¤„ç†æˆåŠŸ: {body['processed']}")
    print(f"  å¤„ç†å¤±è´¥: {body['failed']}")
    print(f"  å¹³å‡å»¶è¿Ÿ: {body['avg_latency_ms']}ms")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {body['cache_hit_rate']}")
    print(f"  ååé‡: {len(user_ids) / (total_time / 1000):.1f} è¯·æ±‚/ç§’")
    
    # P99å»¶è¿Ÿåˆ†æ
    if body['results']:
        latencies = [r['latency_ms'] for r in body['results']]
        latencies.sort()
        p99_index = int(len(latencies) * 0.99)
        p99_latency = latencies[p99_index] if p99_index < len(latencies) else latencies[-1]
        
        print(f"\næ€§èƒ½æŒ‡æ ‡:")
        print(f"  Min latency: {min(latencies)}ms")
        print(f"  Max latency: {max(latencies)}ms")
        print(f"  P50 latency: {latencies[len(latencies)//2]}ms")
        print(f"  P99 latency: {p99_latency}ms {'âœ…' if p99_latency < 100 else 'âš ï¸'}")
        print(f"  P99ç›®æ ‡: <100ms")
    
    return body


def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: ç¼“å­˜æ€§èƒ½æµ‹è¯•")
    print("=" * 80)
    
    user_id = 42
    
    # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
    print(f"\nç¬¬ä¸€æ¬¡è¯·æ±‚ user_id={user_id} (ç¼“å­˜æœªå‘½ä¸­)...")
    event1 = create_kinesis_event([user_id])
    response1 = lambda_handler(event1, MockContext())
    body1 = json.loads(response1['body'])
    latency1 = body1['results'][0]['latency_ms'] if body1['results'] else 0
    from_cache1 = body1['results'][0]['from_cache'] if body1['results'] else False
    
    print(f"  å»¶è¿Ÿ: {latency1}ms")
    print(f"  æ¥è‡ªç¼“å­˜: {from_cache1}")
    
    # ç­‰å¾…ä¸€å°ä¼šå„¿
    time.sleep(0.1)
    
    # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print(f"\nç¬¬äºŒæ¬¡è¯·æ±‚ user_id={user_id} (ç¼“å­˜å‘½ä¸­)...")
    event2 = create_kinesis_event([user_id])
    response2 = lambda_handler(event2, MockContext())
    body2 = json.loads(response2['body'])
    latency2 = body2['results'][0]['latency_ms'] if body2['results'] else 0
    from_cache2 = body2['results'][0]['from_cache'] if body2['results'] else False
    
    print(f"  å»¶è¿Ÿ: {latency2}ms")
    print(f"  æ¥è‡ªç¼“å­˜: {from_cache2}")
    
    # æ€§èƒ½æå‡
    if latency1 > 0 and latency2 > 0:
        improvement = ((latency1 - latency2) / latency1) * 100
        print(f"\nâœ“ ç¼“å­˜æ€§èƒ½æå‡: {improvement:.1f}%")
        print(f"  å»¶è¿Ÿé™ä½: {latency1 - latency2}ms")


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: é”™è¯¯å¤„ç†")
    print("=" * 80)
    
    # åˆ›å»ºåŒ…å«æ— æ•ˆæ•°æ®çš„äº‹ä»¶
    records = []
    
    # æœ‰æ•ˆè¯·æ±‚
    valid_request = {
        "user_id": 1,
        "top_n": 10,
        "request_id": str(uuid.uuid4()),
        "timestamp": datetime.utcnow().isoformat()
    }
    
    # æ— æ•ˆè¯·æ±‚ï¼ˆç¼ºå°‘user_idï¼‰
    invalid_request = {
        "top_n": 10,
        "request_id": str(uuid.uuid4()),
        "timestamp": datetime.utcnow().isoformat()
    }
    
    for req in [valid_request, invalid_request]:
        record = {
            "kinesis": {
                "data": base64.b64encode(json.dumps(req).encode()).decode(),
                "sequenceNumber": str(uuid.uuid4())
            }
        }
        records.append(record)
    
    event = {"Records": records}
    response = lambda_handler(event, MockContext())
    body = json.loads(response['body'])
    
    print(f"\nâœ“ é”™è¯¯å¤„ç†ç»“æœ:")
    print(f"  å¤„ç†æˆåŠŸ: {body['processed']}")
    print(f"  å¤„ç†å¤±è´¥: {body['failed']}")
    
    if body['errors']:
        print(f"\né”™è¯¯è¯¦æƒ…:")
        for error in body['errors']:
            print(f"  - {error['error']}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ Kinesis-Lambdaæ¨èæµç¨‹æµ‹è¯•")
    print("=" * 80)
    print("âš ï¸  ç¡®ä¿FastAPIæœåŠ¡æ­£åœ¨è¿è¡Œ: http://localhost:8082")
    print("=" * 80)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['FASTAPI_ENDPOINT'] = os.environ.get('FASTAPI_ENDPOINT', 'http://localhost:8082')
    os.environ['REDIS_ENABLED'] = os.environ.get('REDIS_ENABLED', 'false')
    
    print(f"\né…ç½®:")
    print(f"  FastAPI Endpoint: {os.environ['FASTAPI_ENDPOINT']}")
    print(f"  Redis Enabled: {os.environ['REDIS_ENABLED']}")
    
    try:
        # è¿è¡Œæµ‹è¯•
        test_single_user()
        test_batch_users()
        
        # ç¼“å­˜æµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨äº†Redisï¼‰
        if os.environ.get('REDIS_ENABLED') == 'true':
            test_cache_performance()
        else:
            print("\nâš ï¸  è·³è¿‡ç¼“å­˜æµ‹è¯•ï¼ˆRedisæœªå¯ç”¨ï¼‰")
            print("   è¦æµ‹è¯•ç¼“å­˜ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡: REDIS_ENABLED=true REDIS_ENDPOINT=localhost")
        
        test_error_handling()
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 80)
        
        print("\nğŸ“ æ€»ç»“:")
        print("  âœ“ Lambdaå‡½æ•°å¯ä»¥æ­£ç¡®å¤„ç†Kinesisäº‹ä»¶")
        print("  âœ“ æ¨èæœåŠ¡å“åº”æ­£å¸¸")
        print("  âœ“ é”™è¯¯å¤„ç†æœºåˆ¶å·¥ä½œæ­£å¸¸")
        if os.environ.get('REDIS_ENABLED') == 'true':
            print("  âœ“ Redisç¼“å­˜æä¾›æ˜¾è‘—æ€§èƒ½æå‡")
        print("\nğŸ¯ æ¶æ„å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥éƒ¨ç½²åˆ°AWS!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()


